{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eee61c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db87533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_ci = pd.read_csv('customer_interactions.csv')\n",
    "df_pd = pd.read_csv('product_details.csv', delimiter=',')\n",
    "df_ph = pd.read_csv('purchase_history.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51e3cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_ph, df_ci, on='customer_id', how='left')\n",
    "df = pd.merge(df_merge, df_pd, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac02a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2199: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n",
      "  result, tz_parsed = tslib.array_to_datetime(\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# Customer Behavior Features\n",
    "df['total_page_views'] = df.groupby('customer_id')['page_views'].transform('sum')\n",
    "df['average_time_spent'] = df.groupby('customer_id')['time_spent'].transform('mean')\n",
    "\n",
    "# Purchase History Features\n",
    "df['total_purchases'] = df.groupby('customer_id')['product_id'].transform('nunique')\n",
    "df['recency_of_purchase'] = (pd.to_datetime('now') - pd.to_datetime(df['purchase_date'])).dt.days\n",
    "\n",
    "# Product Interaction Features\n",
    "df['average_rating_purchased'] = df.groupby('customer_id')['ratings'].transform('mean')\n",
    "df['average_price_purchased'] = df.groupby('customer_id')['price'].transform('mean')\n",
    "\n",
    "# Temporal Features\n",
    "df['purchase_month'] = pd.to_datetime(df['purchase_date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "827a2911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>page_views</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>ratings</th>\n",
       "      <th>total_page_views</th>\n",
       "      <th>average_time_spent</th>\n",
       "      <th>total_purchases</th>\n",
       "      <th>recency_of_purchase</th>\n",
       "      <th>average_rating_purchased</th>\n",
       "      <th>average_price_purchased</th>\n",
       "      <th>purchase_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>500</td>\n",
       "      <td>4.5</td>\n",
       "      <td>500</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9</td>\n",
       "      <td>360</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>471.700000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>800</td>\n",
       "      <td>4.8</td>\n",
       "      <td>500</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9</td>\n",
       "      <td>356</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>471.700000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>50</td>\n",
       "      <td>3.8</td>\n",
       "      <td>160</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5</td>\n",
       "      <td>359</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>404.625000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>200</td>\n",
       "      <td>4.2</td>\n",
       "      <td>240</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5</td>\n",
       "      <td>358</td>\n",
       "      <td>3.712500</td>\n",
       "      <td>496.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>240</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6</td>\n",
       "      <td>357</td>\n",
       "      <td>4.043750</td>\n",
       "      <td>282.125000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>27</td>\n",
       "      <td>104</td>\n",
       "      <td>2023-01-18 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>92</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>264</td>\n",
       "      <td>92.0</td>\n",
       "      <td>9</td>\n",
       "      <td>343</td>\n",
       "      <td>3.925000</td>\n",
       "      <td>480.416667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>49</td>\n",
       "      <td>105</td>\n",
       "      <td>2023-09-17 00:00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>127</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>800</td>\n",
       "      <td>4.8</td>\n",
       "      <td>160</td>\n",
       "      <td>127.0</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>476.700000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>72</td>\n",
       "      <td>102</td>\n",
       "      <td>2023-05-07 00:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>116</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>50</td>\n",
       "      <td>3.8</td>\n",
       "      <td>204</td>\n",
       "      <td>116.0</td>\n",
       "      <td>7</td>\n",
       "      <td>234</td>\n",
       "      <td>3.783333</td>\n",
       "      <td>243.583333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>55</td>\n",
       "      <td>107</td>\n",
       "      <td>2023-09-22 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>120</td>\n",
       "      <td>Books</td>\n",
       "      <td>783</td>\n",
       "      <td>3.8</td>\n",
       "      <td>220</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7</td>\n",
       "      <td>96</td>\n",
       "      <td>3.830000</td>\n",
       "      <td>448.100000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>97</td>\n",
       "      <td>107</td>\n",
       "      <td>2023-02-17 00:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>87</td>\n",
       "      <td>Books</td>\n",
       "      <td>783</td>\n",
       "      <td>3.8</td>\n",
       "      <td>208</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4</td>\n",
       "      <td>313</td>\n",
       "      <td>3.725000</td>\n",
       "      <td>614.125000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  product_id        purchase_date  page_views  time_spent  \\\n",
       "0               1         101           2023-01-01          25         120   \n",
       "1               1         105           2023-01-05          25         120   \n",
       "2               2         102           2023-01-02          20          90   \n",
       "3               3         103           2023-01-03          30         150   \n",
       "4               4         104           2023-01-04          15          80   \n",
       "...           ...         ...                  ...         ...         ...   \n",
       "1001           27         104  2023-01-18 00:00:00          22          92   \n",
       "1002           49         105  2023-09-17 00:00:00          16         127   \n",
       "1003           72         102  2023-05-07 00:00:00          17         116   \n",
       "1004           55         107  2023-09-22 00:00:00          22         120   \n",
       "1005           97         107  2023-02-17 00:00:00          26          87   \n",
       "\n",
       "            category  price  ratings  total_page_views  average_time_spent  \\\n",
       "0        Electronics    500      4.5               500               120.0   \n",
       "1        Electronics    800      4.8               500               120.0   \n",
       "2           Clothing     50      3.8               160                90.0   \n",
       "3     Home & Kitchen    200      4.2               240               150.0   \n",
       "4             Beauty     30      4.0               240                80.0   \n",
       "...              ...    ...      ...               ...                 ...   \n",
       "1001          Beauty     30      4.0               264                92.0   \n",
       "1002     Electronics    800      4.8               160               127.0   \n",
       "1003        Clothing     50      3.8               204               116.0   \n",
       "1004           Books    783      3.8               220               120.0   \n",
       "1005           Books    783      3.8               208                87.0   \n",
       "\n",
       "      total_purchases  recency_of_purchase  average_rating_purchased  \\\n",
       "0                   9                  360                  4.040000   \n",
       "1                   9                  356                  4.040000   \n",
       "2                   5                  359                  3.937500   \n",
       "3                   5                  358                  3.712500   \n",
       "4                   6                  357                  4.043750   \n",
       "...               ...                  ...                       ...   \n",
       "1001                9                  343                  3.925000   \n",
       "1002                8                  101                  3.980000   \n",
       "1003                7                  234                  3.783333   \n",
       "1004                7                   96                  3.830000   \n",
       "1005                4                  313                  3.725000   \n",
       "\n",
       "      average_price_purchased  purchase_month  \n",
       "0                  471.700000               1  \n",
       "1                  471.700000               1  \n",
       "2                  404.625000               1  \n",
       "3                  496.250000               1  \n",
       "4                  282.125000               1  \n",
       "...                       ...             ...  \n",
       "1001               480.416667               1  \n",
       "1002               476.700000               9  \n",
       "1003               243.583333               5  \n",
       "1004               448.100000               9  \n",
       "1005               614.125000               2  \n",
       "\n",
       "[1006 rows x 15 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b4d873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                   int64\n",
       "product_id                    int64\n",
       "purchase_date                object\n",
       "page_views                    int64\n",
       "time_spent                    int64\n",
       "category                     object\n",
       "price                         int64\n",
       "ratings                     float64\n",
       "total_page_views              int64\n",
       "average_time_spent          float64\n",
       "total_purchases               int64\n",
       "recency_of_purchase           int64\n",
       "average_rating_purchased    float64\n",
       "average_price_purchased     float64\n",
       "purchase_month                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "deace537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def predict_product(latest_customer_id):\n",
    "\n",
    "        # Preprocess data (Replace with actual preprocessing logic)\n",
    "        features = df[['page_views', 'time_spent', 'price', 'ratings', 'recency_of_purchase', 'purchase_month']]\n",
    "        target = df['product_id']\n",
    "\n",
    "        # Splitting the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Train the Random Forest model\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Convert 'purchase_date' to datetime if it's not already\n",
    "        df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "\n",
    "        # Sort the DataFrame by 'purchase_date' in descending order (latest first)\n",
    "        terra_df_sorted = df.sort_values(by='purchase_date', ascending=False)\n",
    "\n",
    "        # Fetch latest customer's data for prediction\n",
    "        latest_customer_data = terra_df_sorted[terra_df_sorted['customer_id'] == latest_customer_id].iloc[0]\n",
    "        latest_features = latest_customer_data[['page_views', 'time_spent', 'price', 'ratings', 'recency_of_purchase', 'purchase_month']]\n",
    "\n",
    "        # Predict the product\n",
    "        predicted_product_id = model.predict([latest_features])[0]\n",
    "        return predicted_product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9ae46d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_product(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac93c00",
   "metadata": {},
   "source": [
    "**The use of a RandomForestClassifier in the model for predicting the next product purchase can be attributed to several inherent advantages of this algorithm**, particularly for classification tasks like yours. Here's why RandomForestClassifier is a suitable choice:\n",
    "\n",
    "- **Handling of Both Categorical and Numerical Data:** RandomForest can naturally handle a mix of different feature types â€“ in your case, both numerical (like page_views, time_spent, price, ratings, recency_of_purchase) and categorical data (purchase_month).\n",
    "\n",
    "- **Robustness to Overfitting:** RandomForest, being an ensemble method that builds multiple decision trees and merges their outcomes, tends to be more robust against overfitting compared to individual decision trees. This is especially useful when you have a complex dataset.\n",
    "\n",
    "- **Ability to Handle Non-Linear Relationships:** RandomForest can capture non-linear relationships between features and the target variable, which might be present in your dataset.\n",
    "\n",
    "- **No Need for Feature Scaling:** RandomForest does not require feature scaling (like standardization or normalization) to be effective, which simplifies the preprocessing steps.\n",
    "\n",
    "- **Handling Missing Values:** While your script does not explicitly handle missing values, RandomForest can handle them internally to some extent, which can be useful in many real-world datasets.\n",
    "\n",
    "- **Feature Importance:** RandomForest can provide insights into the importance of different features in predicting the target variable, which can be valuable for understanding your model and the underlying data.\n",
    "\n",
    "- **Good Performance with Default Parameters:** RandomForest often provides reasonably good results with default parameter settings, making it a good starting point for model development.\n",
    "\n",
    "- **Versatility:** It is a versatile algorithm that can be a good first choice for many classification problems and usually performs well compared to other algorithms without extensive hyperparameter tuning.\n",
    "\n",
    "**Why Not Other Algorithms?**\n",
    "\n",
    "Linear Models (like Logistic Regression) might not perform well if the relationship between features and target variable is non-linear or complex.\n",
    "\n",
    "SVM (Support Vector Machine) can be effective for classification tasks, but it may require careful tuning of hyperparameters and feature scaling.\n",
    "\n",
    "Neural Networks could be an alternative, but they typically require more data, more computational resources, and more effort in tuning.\n",
    "\n",
    "**In summary,** RandomForest provides a good balance between performance and ease of use, making it a suitable choice for many classification tasks, including yours. However, it's always a good idea to experiment with different models and compare their performance to find the best one for your specific dataset and problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc938dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
